# ğŸš€ Production-Ready Microservices Deployment with Docker & Nginx

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://docker.com)
[![Go](https://img.shields.io/badge/Go-00ADD8?style=flat&logo=go&logoColor=white)](https://golang.org)
[![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)](https://python.org)
[![Nginx](https://img.shields.io/badge/Nginx-009639?style=flat&logo=nginx&logoColor=white)](https://nginx.org)
[![Production](https://img.shields.io/badge/Production-Ready-brightgreen)](https://github.com/niranjan-46/nginx-docker-assignment)

A production-grade containerized microservices architecture demonstrating real-time deployment strategies using Nginx as a reverse proxy, Docker containerization, and multi-service orchestration.

## ğŸ¯ Overview

This repository demonstrates **real-time microservices deployment** patterns used in production environments. The project showcases how enterprises deploy scalable, containerized applications using industry-standard tools and practices.

### ğŸ¢ Production Use Cases:
- **API Gateway Pattern** - Single entry point for multiple services
- **Service Mesh Architecture** - Inter-service communication and routing
- **Container Orchestration** - Scalable deployment and management
- **Load Balancing** - Traffic distribution across service instances
- **Health Monitoring** - Real-time service health checks and monitoring

This architecture is commonly used by companies like Netflix, Spotify, and Amazon for their microservices infrastructure.

## ğŸ—ï¸ Production Architecture

```
ğŸŒ Internet/Load Balancer
    â†“
ğŸ” SSL/TLS Termination
    â†“
ğŸŒ Client Requests â†’ ğŸ”„ Nginx Reverse Proxy (Port 8080)
    â†“
ğŸ¯ Service Discovery & Routing
    â”œâ”€â”€ ğŸ“ /api/v1/service1/* â†’ ğŸŸ¢ Go Microservice (Port 8001)
    â”‚   â”œâ”€â”€ ğŸ’¾ Database Connection Pool
    â”‚   â”œâ”€â”€ ğŸ“Š Metrics & Monitoring
    â”‚   â””â”€â”€ ğŸ”„ Auto-scaling Ready
    â”‚
    â””â”€â”€ ğŸ“ /api/v1/service2/* â†’ ğŸ Python Microservice (Port 8002)
        â”œâ”€â”€ ğŸ’¾ Database Connection Pool
        â”œâ”€â”€ ğŸ“Š Metrics & Monitoring
        â””â”€â”€ ğŸ”„ Auto-scaling Ready
```

## âš¡ Prerequisites

### ğŸ› ï¸ **Required Tools:**
- ğŸ³ [Docker](https://docs.docker.com/get-docker/) (v20.10+)
- ğŸ”§ [Docker Compose](https://docs.docker.com/compose/install/) (v2.0+)
- ğŸ’» [Git](https://git-scm.com/) for version control

### ğŸ¢ **Production Environment Requirements:**
- ğŸ–¥ï¸ **Server Specs**: 2+ CPU cores, 4GB+ RAM
- ğŸŒ **Network**: Port 8080 accessible (or configure load balancer)
- ğŸ“ **Storage**: 10GB+ available disk space
- ğŸ” **Security**: Firewall configured for container networking

## ğŸš€ Production Deployment

### ğŸ¢ **Enterprise Deployment**

```bash
# ğŸ“¦ Clone the production repository
git clone -b feature/nginx-docker-assignment https://github.com/niranjan-46/nginx-docker-assignment.git
cd nginx-docker-assignment

# ğŸ” Set production environment variables
export ENVIRONMENT=production
export LOG_LEVEL=info
export NGINX_WORKER_PROCESSES=auto

# ğŸ—ï¸ Build and deploy with production configuration
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up --build -d

# ğŸ” Verify deployment status
docker-compose ps
docker-compose logs --tail=50
```

### ğŸ§ **Linux Production Server**

```bash
# ğŸ”§ Install Docker & Docker Compose (Production versions)
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# ğŸ“¥ Install Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# ğŸš€ Deploy the application
git clone -b feature/nginx-docker-assignment https://github.com/niranjan-46/nginx-docker-assignment.git
cd nginx-docker-assignment
docker-compose up --build -d
```

### â˜ï¸ **Cloud Deployment (AWS/GCP/Azure)**

```bash
# ğŸŒ For cloud deployment, additional considerations:
# - Use managed container services (ECS, GKE, AKS)
# - Configure load balancers and auto-scaling
# - Set up SSL certificates
# - Configure monitoring and logging

# Example AWS deployment:
# 1. Push images to ECR
# 2. Deploy via ECS or EKS
# 3. Configure ALB for load balancing
```

### ğŸ”¨ Build & Startup (Docker Compose)

![Build Stage](images/image3.png)

*ğŸ—ï¸ Docker Compose building and starting all services*

```log
âœ… Building nginx...
âœ… Building service1...
âœ… Building service2...
ğŸš€ Starting nginx-proxy_nginx_1...
ğŸš€ Starting nginx-proxy_service1_1...
ğŸš€ Starting nginx-proxy_service2_1...
ğŸŸ¢ All services are up and running!
```

## ğŸ¯ Usage

Once the services are running, access the application at: 
> ğŸŒ **http://localhost:8080**

### ğŸ§ª Testing the Services

**ğŸŸ¢ Go Service (/service1)**:

![Service 1 - Go Backend](images/image1.png)

*ğŸš€ Go service endpoints and responses*

```bash
# ğŸ“ Ping test
curl http://localhost:8080/service1/ping
# Response: {"message": "pong", "service": "go-service"}

# ğŸ‘‹ Hello endpoint
curl http://localhost:8080/service1/hello
# Response: {"message": "Hello from Go Service!", "timestamp": "2024-01-15T10:30:00Z"}

# ğŸ’š Health check
curl http://localhost:8080/service1/health
# Response: {"status": "healthy", "service": "go-service", "uptime": "2h30m"}
```

**ğŸ Python Service (/service2)**:

![Service 2 - Python Backend](images/image2.png)

*ğŸ”¥ Python service endpoints and responses*

```bash
# ğŸ“ Ping test
curl http://localhost:8080/service2/ping
# Response: {"message": "pong", "service": "python-service"}

# ğŸ‘‹ Hello endpoint
curl http://localhost:8080/service2/hello
# Response: {"message": "Hello from Python Service!", "timestamp": "2024-01-15T10:30:00Z"}

# ğŸ’š Health check
curl http://localhost:8080/service2/health
# Response: {"status": "healthy", "service": "python-service", "uptime": "2h30m"}
```

## ğŸ“ Project Structure

```
ğŸ“‚ nginx-docker-assignment/
â”œâ”€â”€ ğŸ³ docker-compose.yml         # Docker Compose configuration
â”œâ”€â”€ ğŸ“‚ nginx/
â”‚   â”œâ”€â”€ âš™ï¸ nginx.conf             # Nginx reverse proxy rules
â”‚   â””â”€â”€ ğŸ³ Dockerfile             # Nginx container build
â”œâ”€â”€ ğŸ“‚ service_1/                 # Go microservice
â”‚   â”œâ”€â”€ ğŸŸ¢ main.go
â”‚   â”œâ”€â”€ ğŸ“¦ go.mod
â”‚   â””â”€â”€ ğŸ³ Dockerfile
â”œâ”€â”€ ğŸ“‚ service_2/                 # Python microservice
â”‚   â”œâ”€â”€ ğŸ app.py
â”‚   â”œâ”€â”€ ğŸ“‹ requirements.txt
â”‚   â””â”€â”€ ğŸ³ Dockerfile
â””â”€â”€ ğŸ“– README.md                  # Project documentation
```

## âš™ï¸ How It Works

**ğŸ”„ Nginx Reverse Proxy**: Nginx listens on port 8080 and routes incoming requests to the appropriate backend services based on URL paths.

- ğŸ“ `/service1/*` â†’ ğŸŸ¢ Go service running on port 8001
- ğŸ“ `/service2/*` â†’ ğŸ Python service running on port 8002

Each service provides the following endpoints:

- ğŸ“ `/ping` â€” Connectivity check
- ğŸ‘‹ `/hello` â€” Test response  
- ğŸ’š `/health` â€” Health check

**ğŸ³ Containerization**: All services are containerized using Docker and orchestrated with Docker Compose for easy deployment.

### ğŸŒŠ Architecture Flow

The following images show the complete workflow:

## ğŸ® Production Operations

### ğŸš€ **Deployment Commands**
```bash
# ğŸ—ï¸ Production build and deploy
docker-compose up --build -d --scale service1=3 --scale service2=2
```
```log
ğŸ” Pulling latest images...
ğŸ—ï¸ Building production containers...
ğŸš€ Scaling service1 to 3 instances...
ğŸš€ Scaling service2 to 2 instances...
âœ… Production deployment complete - Load balanced across multiple instances
```

### ğŸ”„ **Zero-Downtime Updates**
```bash
# ğŸ”„ Rolling update strategy
docker-compose up --build --no-deps --scale service1=6 service1
docker-compose up --build --no-deps --scale service1=3 service1
```

### ğŸ“Š **Production Monitoring**
```bash
# ğŸ“ˆ View real-time metrics
docker stats

# ğŸ“‹ Tail production logs
docker-compose logs -f --tail=100

# ğŸ” Health check all services
curl http://localhost:8080/health
curl http://localhost:8080/service1/health
curl http://localhost:8080/service2/health
```

### ğŸ›‘ **Graceful Shutdown**
```bash
# ğŸ›‘ Graceful production shutdown
docker-compose down --timeout 30
```
```log
â³ Stopping containers gracefully (30s timeout)...
ğŸ›‘ service1_1 exited gracefully
ğŸ›‘ service2_1 exited gracefully  
ğŸ›‘ nginx_1 stopped
âœ… All services stopped without data loss
```

## ğŸ› ï¸ Production Technology Stack

### ğŸ¢ **Core Technologies**
- ğŸ”„ **Nginx** - High-performance reverse proxy and load balancer
- ğŸŸ¢ **Go** - High-concurrency backend service (Gin/Echo framework)
- ğŸ **Python** - Microservice with FastAPI/Flask for rapid development
- ğŸ³ **Docker** - Container runtime and image management
- ğŸ”§ **Docker Compose** - Multi-container orchestration and service mesh

### ğŸ“Š **Production Features**
- ğŸ” **Security** - Rate limiting, CORS, security headers
- ğŸ“ˆ **Monitoring** - Prometheus metrics, health checks, logging
- âš¡ **Performance** - Connection pooling, caching, compression
- ğŸ”„ **Reliability** - Auto-restart, graceful shutdown, circuit breakers
- ğŸ“± **API Design** - RESTful APIs with OpenAPI/Swagger documentation

## ğŸ©¹ Troubleshooting Build Issues

If you encounter build issues, try cleaning up old containers and images:

```bash
# ğŸ§¹ Complete cleanup
docker-compose down -v --remove-orphans
docker system prune -f
docker-compose build --no-cache
docker-compose up
```

```log
âš ï¸  Removing containers and volumes...
ğŸ§¹ Pruning system resources...
ğŸ—ï¸ Building without cache...
âœ… Fresh build completed successfully!
```

### ğŸ” Common Issues & Solutions

| âŒ Issue | ğŸ’¡ Solution |
|----------|-------------|
| Port 8080 already in use | `sudo lsof -i :8080` then kill the process |
| Docker daemon not running | `sudo systemctl start docker` |
| Permission denied | `sudo usermod -aG docker $USER` then logout/login |
| Build fails | Run cleanup commands above |

## ğŸ‘¨â€ğŸ’» Author & Contributors

**Niranjan** ğŸš€  
ğŸ“§ **DevOps Engineer & Solution Architect**  
ğŸ”— GitHub: [@niranjan-46](https://github.com/niranjan-46)  
ğŸ¢ **Specialization**: Microservices Architecture, Container Orchestration, Production Deployment

### ğŸ¤ **Contributing**
This project welcomes contributions from the community! Whether you're fixing bugs, adding features, or improving documentation - all contributions are valued.

## ğŸ“ˆ **Production Adoption**

This architecture pattern is successfully used by:
- ğŸ¢ **Startups** scaling from monolith to microservices
- ğŸ­ **Enterprises** modernizing legacy applications  
- â˜ï¸ **Cloud-native** applications requiring high availability
- ğŸŒ **SaaS platforms** needing multi-tenant architecture

## ğŸ“œ **License & Usage**

â­ **Star this repo** if it helped your production deployment!  
ğŸ´ **Fork it** to customize for your use case  
ğŸ“¤ **Share it** with your team and community

---

<div align="center">

### ğŸ‰ Deploy with Confidence!

**Production-Ready Microservices Architecture**

[![GitHub stars](https://img.shields.io/github/stars/niranjan-46/nginx-docker-assignment?style=social)](https://github.com/niranjan-46/nginx-docker-assignment)
[![GitHub forks](https://img.shields.io/github/forks/niranjan-46/nginx-docker-assignment?style=social)](https://github.com/niranjan-46/nginx-docker-assignment)
[![Docker Pulls](https://img.shields.io/badge/Docker-Production--Ready-blue)](https://github.com/niranjan-46/nginx-docker-assignment)

*Used by production teams worldwide for reliable microservices deployment* ğŸŒ

</div>
